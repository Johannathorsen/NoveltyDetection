{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_class = 1 #choose which class to exclude\n",
    "\n",
    "'''Import data and create novel class'''\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "X_features = np.load(\"X.npy\")\n",
    "Y_features = np.load(\"Y.npy\")\n",
    "\n",
    "'''Display all classes'''\n",
    "categories = np.unique(Y_features)\n",
    "print (\"Classes: %s\" %' '.join(map(str, categories)))\n",
    "categories = np.delete(categories, novel_class)\n",
    "print (\"Novel class: %s\" %(novel_class))\n",
    "print (\"Classes after removal of novel: %s\" %' '.join(map(str, categories)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_novelties = np.load(\"X.npy\")\n",
    "Y_novelties = []\n",
    "for i in range(len(X_novelties)):\n",
    "Y_novelties.append(novel_class)\n",
    "Y_novelties = np.array(Y_novelties)\n",
    "X_features = np.concatenate((X_dataset, X_novelties))\n",
    "Y_features = np.concatenate((Y_dataset, Y_novelties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Split the known classes into test sets'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_TR, X_TE, Y_TR, Y_TE = train_test_split(X_features, Y_features, test_size=0.2, random_state=555, stratify=Y_features)\n",
    "X_TEK, X_TEM, Y_TEK, Y_TEM = train_test_split(X_TE, Y_TE, test_size=0.5, random_state=555, stratify=Y_TE)\n",
    "\n",
    "Y_train, X_train, Y_test_known, X_test_known = [],[],[],[] #New arrays for deleting novel data\n",
    "for i in range(len(Y_TEK)): #creating testing set without novel data\n",
    "    if Y_TEK[i] != novel_class:\n",
    "        Y_test_known.append(Y_TEK[i])\n",
    "        X_test_known.append(X_TEK[i])\n",
    "for i in range(len(Y_TR)): #creating training test without novel data\n",
    "    if Y_TR[i] != novel_class:\n",
    "        Y_train.append(Y_TR[i])\n",
    "        X_train.append(X_TR[i])\n",
    "Y_test_mix, X_test_mix = Y_TEM, X_TEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''2nd Run: Take away novel data from mixed dataset'''\n",
    "Y_test_mix, X_test_mix = [],[]\n",
    "for i in range(len(Y_TEM)):\n",
    "    if Y_TEM[i] != novel_class:\n",
    "        Y_test_mix.append(Y_TEM[i])\n",
    "        X_test_mix.append(X_TEM[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Train and fit an GP'''\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "clf = OneVsRestClassifier(GaussianProcessClassifier(kernel=1.0 * RBF(length_scale=1.0), random_state=555))\n",
    "clf.fit(X_train,Y_train)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "'''Predicting test data and calculating probabilites'''\n",
    "start = time.time()\n",
    "Y_pred_known = clf.predict(X_test_known)\n",
    "Y_score_known = clf.predict_proba(X_test_known)\n",
    "Y_PM = clf.predict(X_test_mix)\n",
    "Y_score_mix = clf.predict_proba(X_test_mix)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Binarize labels'''\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "n_classes = len(categories)\n",
    "Y_test_known = label_binarize(Y_test_known, classes=categories) #classes: skipping novel\n",
    "Y_train = label_binarize(Y_train, classes=categories) #classes: skipping novel\n",
    "Y_TEM = label_binarize(Y_test_mix, classes=range(n_classes+1)) #classes: including novel\n",
    "Y_pred_known = label_binarize(Y_pred_known, classes=categories) #classes: skipping novel\n",
    "Y_PM = label_binarize(Y_PM, classes=categories) #classes: skipping novel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Rearranging the novel class to the end of the Y_test_mix-label'''\n",
    "Y_TEM_R = []\n",
    "for i in range(len(Y_TEM)):\n",
    "    new_ = []\n",
    "    new_.extend(Y_TEM[i][:novel_class])\n",
    "    new_.extend(Y_TEM[i][(novel_class+1):])\n",
    "    new_.append(Y_TEM[i][novel_class])\n",
    "    Y_TEM_R.append(new_)\n",
    "Y_test_mix = np.array(Y_TEM_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Deciding thresholds for each class'''\n",
    "threshold_array = []\n",
    "for i in range(len(categories)): #going through all but the novel class\n",
    "    max_score_known = []\n",
    "    for j in range(len(Y_pred_known)):\n",
    "        max_score_known.append(max(Y_score_known[j]))\n",
    "    max_score_mix = []\n",
    "    for j in range(len(Y_PM)):\n",
    "        max_score_mix.append(max(Y_score_mix[j]))\n",
    "        \n",
    "    mean_mix = np.mean(max_score_mix)\n",
    "    mean_known = np.mean(max_score_known)\n",
    "    sorted_mixed = np.sort(max_score_mix)\n",
    "    times = 0\n",
    "    threshold = 0\n",
    "    if mean_known < mean_mix:\n",
    "    print ('Mean with novels is higher than mixed: %f vs %f' %(mean_mix, mean_known))\n",
    "    while mean_mix < mean_known:\n",
    "        threshold = sorted_mixed[0]\n",
    "        sorted_mixed = np.delete(sorted_mixed, 0)\n",
    "        mean_mix = np.mean(sorted_mixed)\n",
    "        times += 1\n",
    "    print ('The threshold will be %f and we will consider %d data as novel' %(threshold, times))\n",
    "    threshold_array.append(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Creating a novel class and moving all novel data to that class'''\n",
    "novel_list = []\n",
    "max_scores_known = []\n",
    "\n",
    "novel_class_array = [] #creating array with all zeros except the last (which is one, representing the novel class)\n",
    "for i in range(len(categories)):\n",
    "    novel_class_array.append(0)\n",
    "novel_class_array.append(1)\n",
    "\n",
    "Y_pred_mix = []\n",
    "number_of_novels = []\n",
    "for i in range(len(Y_PM)): #going through all predicted data\n",
    "    i_class = Y_PM[i].argmax(axis=0)\n",
    "    if max(Y_score_mix[i]) <= threshold_array[Y_PM[i].argmax(axis=0)]: #checking if it's under the threshold\n",
    "        Y_pred_mix.append(novel_class_array)\n",
    "        novel_list.append([max(Y_score_mix[i]), Y_test_mix[i]])\n",
    "        number_of_novels.append(i_class)\n",
    "    else:\n",
    "        Y_pred_mix.append(np.concatenate((Y_PM[i], [0])))\n",
    "        max_scores_known.append([max(Y_score_mix[i]), Y_test_mix[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Printing number of removed data for each class'''\n",
    "Y_pred_mix = np.array(Y_pred_mix)\n",
    "from collections import Counter\n",
    "\n",
    "countering = Counter(number_of_novels)\n",
    "for key, value in countering.items():\n",
    "    if key < novel_class:\n",
    "        print (key, value)\n",
    "    else:\n",
    "        print (key+1, value)\n",
    "\n",
    "'''Calculating percentiles'''\n",
    "SUM_NOVEL = 0\n",
    "for i in range(len(Y_test_mix)):\n",
    "    if Y_test_mix[i].argmax(axis=0) == n_classes: #if it's novel data\n",
    "        SUM_NOVEL += 1\n",
    "        \n",
    "unassigned = sorted(unassigned, key=lambda x: x[0])\n",
    "\n",
    "novel_list = sorted(novel_list, key=lambda x: x[0]) \n",
    "max_scores_known = sorted(max_scores_known, key=lambda x: x[0])\n",
    "\n",
    "chosen_list = novel_list \n",
    "chosen_list.extend(max_scores_known) \n",
    "\n",
    "\n",
    "def listed_novels(chosen_list): #for evaluating datasets with a few novelties\n",
    "    no_of_novelties = 0\n",
    "    for no_of_data in range(len(chosen_list)):\n",
    "        if chosen_list[no_of_data][1].argmax(axis=0) == n_classes: #if it's a novel class\n",
    "            no_of_novelties += 1\n",
    "            print ('Novelties: %d, Data %d' %(no_of_novelties, no_of_data+1))\n",
    "        if no_of_novelties == SUM_NOVEL:\n",
    "            break\n",
    "\n",
    "def percentiles_calc(chosen_list): #for evaluating datasets with a great amount of novelties\n",
    "    no_of_novelties = 0\n",
    "    PERC = 10\n",
    "    for no_of_data in range(len(chosen_list)):\n",
    "        if chosen_list[no_of_data][1].argmax(axis=0) == n_classes: #if it's a novel class\n",
    "            no_of_novelties += 1\n",
    "        if no_of_novelties == round(SUM_NOVEL*0.1, 0) and PERC == 10: #the 10th percentile\n",
    "            print 'The precision at the 10th percentile: %f'%(float(no_of_novelties)/(no_of_data+1)*100)\n",
    "            PERC = 25\n",
    "        elif no_of_novelties == round(SUM_NOVEL*0.25, 0) and PERC == 25: #the 25th percentile\n",
    "            print 'The precision at the 25th percentile: %f'%(float(no_of_novelties)/(no_of_data+1)*100)\n",
    "            PERC = 50\n",
    "        elif no_of_novelties == round(SUM_NOVEL*0.50, 0) and PERC == 50: #the 50th percentile\n",
    "            print 'The precision at the 50th percentile: %f'%(float(no_of_novelties)/(no_of_data+1)*100)\n",
    "            PERC = 75\n",
    "        elif no_of_novelties == round(SUM_NOVEL*0.75, 0) and PERC == 75: #the 75th percentile\n",
    "            print 'The precision at the 75th percentile: %f'%(float(no_of_novelties)/(no_of_data+1)*100)\n",
    "            PERC = 100\n",
    "        elif no_of_novelties == SUM_NOVEL: #all data\n",
    "            print 'The precision at the 100th percentile: %f'%(float(no_of_novelties)/(no_of_data+1)*100)\n",
    "            break\n",
    "\n",
    "print ('The predicted classes first:')\n",
    "percentiles_calc(chosen_list)\n",
    "\n",
    "print ('Small dataset, predicted classes first:')\n",
    "percentiles_list(chosen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Evaluation metrics'''\n",
    "\n",
    "'''Overall Prediction accuracy'''\n",
    "print ('Overall prediction accuracy:')\n",
    "from sklearn.metrics import accuracy_score\n",
    "overall_accuracy_known = accuracy_score(Y_test_known, Y_pred_known)\n",
    "overall_accuracy_mix = accuracy_score(Y_test_mix, Y_pred_mix)\n",
    "print (overall_accuracy_known)\n",
    "print (overall_accuracy_mix)\n",
    "\n",
    "'''Classification report'''\n",
    "print ('Classification report:')\n",
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(Y_test_known, Y_pred_known, target_names=''.join(map(str, range(n_classes)))))\n",
    "print (classification_report(Y_test_mix, Y_pred_mix, target_names=''.join(map(str, range(n_classes+1)))))\n",
    "\n",
    "'''Confusion matrices - one with number of data and one normalized'''\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\", \n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test_mix.argmax(axis=1), Y_pred_mix.argmax(axis=1))\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=''.join(map(str, range(n_classes+1))), title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=''.join(map(str, range(n_classes+1))), normalize=True, title='Normalized confusion matrix')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
